{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=1\n",
      "env: MKL_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=1\n",
    "%env MKL_NUM_THREADS=1\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.aq import _dequantize_weight\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = 4096\n",
    "in_features = 4096\n",
    "out_group_size = 1\n",
    "in_group_size = 32\n",
    "out_group_size = 1\n",
    "num_codebooks = 4\n",
    "nbits_per_codebook = 8\n",
    "dtype = torch.float32\n",
    "\n",
    "num_input_groups = in_features // in_group_size\n",
    "codebooks = torch.randn(num_codebooks, 2**nbits_per_codebook, out_group_size, in_group_size, dtype=dtype)\n",
    "codes = torch.randint(0, 2**nbits_per_codebook, \n",
    "                  size=(out_features, num_input_groups, num_codebooks), dtype=torch.uint8)\n",
    "scales = torch.rand(out_features, 1, 1, 1, dtype=dtype)\n",
    "x = torch.randn(1, in_features, dtype=dtype)/ 100\n",
    "\n",
    "w = _dequantize_weight(codes, codebooks, scales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 446 ms, sys: 129 µs, total: 447 ms\n",
      "Wall time: 444 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    y = x @ w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numpy = x.numpy()\n",
    "w_numpy = w.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 437 ms, sys: 13 µs, total: 437 ms\n",
      "Wall time: 437 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    x_numpy @ w_numpy.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_alt = torch.permute(codes, (1, 0, 2)).contiguous()  #  [num_in_groups, num_out_groups, num_codebooks]\n",
    "# x, codebooks, codes_alt, scales, w = x.numpy(), codebooks.numpy(), codes_alt.numpy(), scales.numpy(), w.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blacksamorez/AQLM/.conda/lib/python3.11/site-packages/numba/core/decorators.py:282: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "@numba.njit(nopython=True, parallel=False)\n",
    "def aqlm_gemv_lut(x, codebooks, codes_alt, scales, in_group_size: int):\n",
    "    lut = x.reshape(-1, in_group_size) @ codebooks.reshape(-1, in_group_size).T\n",
    "    lut = lut.reshape(-1, num_codebooks, 2**nbits_per_codebook)\n",
    "    \n",
    "    output_vec = np.zeros(out_features, dtype=x.dtype)\n",
    "    for j in range(num_input_groups):\n",
    "        for i in range(out_features):\n",
    "            for c in range(num_codebooks):\n",
    "                output_vec[i] += lut[j, c, codes_alt[j, i, c]]\n",
    "    output_vec *= scales.flatten()\n",
    "    return output_vec\n",
    "\n",
    "# _ = aqlm_gemv_lut(x, codebooks, codes_alt, scales)\n",
    "_ = aqlm_gemv_lut(x.numpy(), codebooks.numpy(), torch.permute(codes, (1, 0, 2)).contiguous().numpy(), scales.numpy(), in_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 0 ns, total: 110 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    # aqlm_gemv_lut(x, codebooks, codes_alt, scales)\n",
    "    aqlm_gemv_lut(x.numpy(), codebooks.numpy(), codes.numpy(), scales.numpy(), in_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.81641752e-01,  1.00420463e+00, -8.17836404e-01,  2.20113322e-01,\n",
       "        3.20841908e-01,  7.90404499e-01,  1.88450608e-02,  3.29190046e-02,\n",
       "        2.43881062e-01,  4.57227618e-01,  2.08502576e-01,  1.17066443e+00,\n",
       "       -1.50245607e-01,  5.11013091e-01,  1.17427751e-01,  1.93431258e-01,\n",
       "        1.66756463e+00, -1.48235768e-01, -8.21565628e-01, -2.23852754e+00,\n",
       "        8.29873443e-01,  3.76370281e-01,  7.36643136e-01, -3.63634154e-02,\n",
       "        5.99597931e-01,  1.42398670e-01, -5.82772315e-01, -3.35145175e-01,\n",
       "       -1.25073993e+00, -3.20138186e-01,  2.45220947e+00, -2.49513894e-01,\n",
       "        8.57899427e-01,  2.57896245e-01, -5.26075475e-02, -1.07554531e+00,\n",
       "       -1.08862269e+00, -1.40455818e+00, -1.82120653e-03, -1.09655166e+00,\n",
       "        6.54247105e-01,  6.17258549e-02, -1.26817403e-02, -1.65564388e-01,\n",
       "        1.38416708e+00, -7.27667734e-02,  1.82184052e+00, -3.75634968e-01,\n",
       "        4.39066291e-02,  3.37525159e-01, -1.12479830e+00,  1.00341213e+00,\n",
       "        3.44569683e-02, -5.91130257e-01,  2.96643913e-01, -4.48030263e-01,\n",
       "        7.03712761e-01,  2.51464456e-01,  2.47768790e-01,  1.08464921e+00,\n",
       "        9.49141458e-02, -3.24196696e-01, -4.57171977e-01, -2.97041893e-01,\n",
       "        6.24126315e-01, -3.70370120e-01,  2.33162642e-01,  1.66615143e-01,\n",
       "        5.25691986e-01,  9.23832580e-02,  5.23697734e-01,  6.79899454e-02,\n",
       "       -1.81279564e+00, -2.65045834e+00,  1.30491436e+00,  7.97742844e-01,\n",
       "        7.15851009e-01,  2.62934268e-01, -3.35459054e-01,  5.79868197e-01,\n",
       "        1.58722579e-01,  8.81845877e-02, -4.19898480e-02,  1.63994357e-02,\n",
       "        7.91240335e-01,  5.54352030e-02, -6.70283511e-02, -6.62294030e-01,\n",
       "       -9.54333603e-01, -1.23602398e-01,  3.03457618e-01,  6.29780829e-01,\n",
       "        2.33692944e-01,  5.94238520e-01,  1.33858824e+00, -1.06709503e-01,\n",
       "        2.24222112e-02,  1.84589967e-01, -2.08256984e+00, -6.25953257e-01,\n",
       "       -9.26567689e-02,  3.90399754e-01,  1.19379312e-02, -2.06469789e-01,\n",
       "        5.19657135e-01,  5.31626105e-01, -3.83746400e-02, -4.27333545e-03,\n",
       "       -2.97514319e-01, -4.14283842e-01, -4.97836582e-02, -1.19902492e-01,\n",
       "        4.13144141e-01, -6.65664077e-02,  2.04642987e+00, -3.51560563e-01,\n",
       "       -5.18051744e-01,  5.05056739e-01,  9.65553373e-02,  3.89678448e-01,\n",
       "        2.68585861e-01, -1.96001887e+00, -1.22792649e+00,  1.05238944e-01,\n",
       "        5.57612479e-02, -1.00360192e-01, -9.46709037e-01, -3.62771392e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqlm_gemv_lut(x.numpy(), codebooks.numpy(), torch.permute(codes, (1, 0, 2)).contiguous().numpy(), scales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2816,  1.0042, -0.8178,  ..., -0.2378, -1.2057,  0.1868]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
