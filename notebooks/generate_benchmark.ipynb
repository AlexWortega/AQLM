{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db01015854074c048faf31c217b2f10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e540d6ae24450aa391283a02aaffdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_llama_aqlm.py:   0%|          | 0.00/421 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/BlackSamorez/Llama-2-7b-AQLM-6288ppl-hf:\n",
      "- configuration_llama_aqlm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074d88974191462fb3d8180bc137287d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_llama_aqlm.py:   0%|          | 0.00/65.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/BlackSamorez/Llama-2-7b-AQLM-6288ppl-hf:\n",
      "- modeling_llama_aqlm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/home/blacksamorez/quip-sharp/.conda/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa71fed6247c408bbb789f078631dba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantized_model = AutoModelForCausalLM.from_pretrained(\"BlackSamorez/Llama-2-7b-AQLM-6288ppl-hf\", trust_remote_code=True, low_cpu_mem_usage=True, torch_dtype=\"auto\").cuda()\n",
    "fp16_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", torch_dtype=\"auto\").cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Hi, I'm a newbie here. I'm looking for a good place to learn about the basics of programming.\n",
      "I'm looking for a good place to learn about the basics of programming.\n",
      "I'm looking for a good place to learn about the basics of programming. I'm looking for a good place to learn about the basics of programming. I'm looking for a good place to learn about the basics of programming. I'm looking\n",
      "<s> Hi, I’m Jesse. I’m a 24 year old writer and artist from Canada. I have a degree in English Literature from the University of Toronto. I’m a member of the LGBTQ+ community and a huge supporter of it. I’m a feminist and an intersectional feminist. I’m an atheist. I’m a panromantic asexual. I’m asexual, but I’m\n"
     ]
    }
   ],
   "source": [
    "output = quantized_model.generate(tokenizer(\"Hi\", return_tensors=\"pt\")[\"input_ids\"].cuda(), max_new_tokens=100)\n",
    "print(tokenizer.decode(output[0]))\n",
    "output = fp16_model.generate(tokenizer(\"Hi\", return_tensors=\"pt\")[\"input_ids\"].cuda(), max_new_tokens=100)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 s, sys: 3.48 ms, total: 4.2 s\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output = quantized_model.generate(tokenizer(\"Hi\", return_tensors=\"pt\")[\"input_ids\"].cuda(), max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.91 s, sys: 12.1 ms, total: 2.93 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output = fp16_model.generate(tokenizer(\"Hi\", return_tensors=\"pt\")[\"input_ids\"].cuda(), max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
